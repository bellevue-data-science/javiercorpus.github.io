{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256cf25c",
   "metadata": {},
   "source": [
    "# RAG System\n",
    "\n",
    "#### Javier Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224fe2c",
   "metadata": {},
   "source": [
    "### Assignment Instructions\n",
    "\n",
    "Create a chat like the one in the reading [Building Your First RAG System with Python and OpenAI](https://dev.to/mazyaryousefinia/building-your-first-rag-system-with-python-and-openai-1326) using any Wikipedia page. Be sure to ask your bot at least two separate questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f1a5d",
   "metadata": {},
   "source": [
    "This code is based on the one showed in [Retrieval Augmented Generation with OpenAI and Choma](https://www.youtube.com/watch?v=Cim1lNXvCzY) YouTube video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9022e78",
   "metadata": {},
   "source": [
    "The first thing we are going to do is import all the required libraries:\n",
    "\n",
    " - WikipediaLoader - Used to fetch and load content from Wikipedia articles.\n",
    " - RecursiveCharacterTextSplitter - Used to split long texts into smaller chunks for processing.\n",
    " - Chroma - Used as a vector database for storing and retrieving embeddings.\n",
    " - OpenAIEmbeddings - Used to generate text embeddings using OpenAI's models.\n",
    " - RetrievalQA - Used to create question-answering systems.\n",
    " - PromptTemplate - Used to create reusable templates for structuring LLM prompts.\n",
    " - ChatOpenAI - Used to interact with OpenAI's chat models.\n",
    " - pprint - Used to format and display Python data structures in a readable way.\n",
    "\n",
    "Then we are selecting a model (`gpt-5` in this case), and finally we are creating an instance of the OpenAIEmbeddings class. This class sets up a connection to OpenAI's embedding API. The API key is loaded from the from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0777d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pprint\n",
    "\n",
    "GPT_MODEL = \"gpt-5\"\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e4988",
   "metadata": {},
   "source": [
    "We are going to search Wikipedia for \"Day of the Dead\", just because it's a tradition I personally like. We are loading the first article it finds (https://en.wikipedia.org/wiki/Day_of_the_Dead). The text is then split into smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e5caaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Day of the Dead', 'summary': 'The Day of the Dead (Spanish: Día de (los) Muertos) is a holiday traditionally celebrated on November 1 and 2, though other days, such as October 31 or November 6, may be included depending on the locality. The multi-day holiday involves family and friends gathering to pay respects and  remember friends and family members who have died. These celebrations can take a humorous tone, as celebrants remember amusing events and anecdotes about the departed. It is widely observed in Mexico, where it largely developed, and is also observed in other places, especially by people of Mexican heritage. The observance falls during the Christian period of Allhallowtide. Some argue that there are Indigenous Mexican or ancient Aztec influences that account for the custom, though others see it as a local expression of the Allhallowtide season that was brought to the region by the Spanish; the Day of the Dead has become a way to remember those forebears of Mexican culture. The Day of the Dead is largely seen as having a festive characteristic. \\nTraditions connected with the holiday include honoring the deceased using calaveras and marigold flowers known as cempazúchitl, building home altars called ofrendas with the favorite foods and beverages of the departed, and visiting graves with these items as gifts for the deceased. The celebration is not solely focused on the dead, as it is also common to give gifts to friends such as candy sugar skulls, to share traditional pan de muerto with family and friends, and to write light-hearted and often irreverent verses in the form of mock epitaphs dedicated to living friends and acquaintances, a literary form known as calaveras literarias.\\nIn 2008, the tradition was inscribed in the Representative List of the Intangible Cultural Heritage of Humanity by UNESCO.', 'source': 'https://en.wikipedia.org/wiki/Day_of_the_Dead'}, page_content='The Day of the Dead (Spanish: Día de (los) Muertos) is a holiday traditionally celebrated on')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term = \"Day of the Dead\"\n",
    "docs = WikipediaLoader(query=search_term, load_max_docs=1).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "data = text_splitter.split_documents(docs)\n",
    "data[:1]  # Printing the first chunk to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb14914",
   "metadata": {},
   "source": [
    "We are storing the text locally (`Chroma vector database`) in a directory called `Wiki_DDM` (stands for `Wikipedia - Dia De Muertos`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17ecc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Chroma.from_documents(\n",
    "    data, \n",
    "    embeddings, \n",
    "    ids = [f\"{item.metadata['source']}-{index}\" for index, item in enumerate(data)],\n",
    "    collection_name=\"DayoftheDead-Embeddings\", \n",
    "    persist_directory='Wiki_DDM',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb4299",
   "metadata": {},
   "source": [
    "In this template, we are asking the model to provide answers only from the context provided (this will be the `Chroma vector database`.)\n",
    "\n",
    "If we ask a question that cannot be answered with the given information, we expect the model to reply saying that it does not know the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799689a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a bot that answers questions about Day of the Dead, using only the context provided.\n",
    "If you don't know the answer, simply state that you don't know.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0ee03",
   "metadata": {},
   "source": [
    "We create an instance of the model (`gpt-5` in this example), and we set the temperature to 0 to prevent it from getting too creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97ea4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=GPT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f374bfb",
   "metadata": {},
   "source": [
    "This function gets a query as input, and ask the model to retrieve the answer from the specified source (the `Chroma vector DB` in this case.) We set `return_source_documents` to `False` just to keep the output short. If this value is set to `True`, it will show a very lenghty text after each answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d49098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_without_source = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": PROMPT, },\n",
    "    return_source_documents=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc93292",
   "metadata": {},
   "source": [
    "### Testing the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a359d",
   "metadata": {},
   "source": [
    "The first question is a very basic one: \"What is the Day of the Dead?\" The model found the answer right away, retrieved from Wikipedia (stored in Chroma.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa053c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the Day of the Dead?',\n",
      " 'result': 'The Day of the Dead (Spanish: Día de [los] Muertos) is a largely '\n",
      "           'festive holiday in Mexican culture that serves to remember and '\n",
      "           'honor the deceased, with traditions like using calaveras (skulls) '\n",
      "           'and marigolds.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Day of the Dead?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78a459",
   "metadata": {},
   "source": [
    "The second question is also a basic one (\"When is the Day of the Dead traditionally celebrated?\"), with the information available in Wikipedia. However the model was not able to find it. It responded with an unexpected \"I don't know based on the provided context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d587c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'When is the Day of the Dead traditionally celebrated?',\n",
      " 'result': 'I don’t know based on the provided context.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"When is the Day of the Dead traditionally celebrated?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd2ab2",
   "metadata": {},
   "source": [
    "The third question is a more complex one (\"What is the origin of the Day of the Dead?\"), since there is no definitive answer in the article. However, the model was able to provide a somewhat good summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc49d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the origin of the Day of the Dead?',\n",
      " 'result': 'It originates in Mexican culture (Mexico).'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the origin of the Day of the Dead?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1721a6f",
   "metadata": {},
   "source": [
    "The fourth question was also a basic one (\"What is commonly placed in home altars?\"). The model had no trouble answering it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7f1430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is commonly placed in home altars?',\n",
      " 'result': 'The favorite foods and beverages of the departed.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is commonly placed in home altars?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd304d",
   "metadata": {},
   "source": [
    "This fifth question is a bit tricky (\"What are the differences between home altars and ofrendas?\"). Nonetheless, the model returned the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e26a605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What are the differences between home altars and ofrendas?',\n",
      " 'result': 'There is no difference—“home altars” are called “ofrendas.”'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the differences between home altars and ofrendas?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ae976",
   "metadata": {},
   "source": [
    "The sixth question is also tricky (\"Who is the president of Mexico?\"), since the article mentions a president of Mexico, but it doesn't say who is the current president. The model was perfectly capable of making this distinction and it retuned the expected answer: \"I don't know\", while also mentioning Lazaro Cardenas as president mentioned in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071db03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is the president of Mexico?',\n",
      " 'result': 'I don’t know from the provided context. The only president '\n",
      "           'mentioned is the historical figure Lázaro Cárdenas.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the president of Mexico?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695acd3",
   "metadata": {},
   "source": [
    "When asked a completely off-topic question (\"What are the three main ingredients in a vanilla latte?\"), the model quickly responded with the expected answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28dda816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What are the three main ingredients in a vanilla latte?',\n",
      " 'result': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the three main ingredients in a vanilla latte?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af0383",
   "metadata": {},
   "source": [
    "Just as an experiment, we are elevating the temperature of the model, allowing it to be a little bit more creative. Then we asked the same question as before: Who is the president of Mexico?\n",
    "\n",
    "In the two answers below, the model correctly indentifies Lazaro Cardenas as the president mentioned in the context, but it states it doesn't know who the current president is. This is the expected answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8b1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=1, model=GPT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8efbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is the president of Mexico?', 'result': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the president of Mexico?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c42ce1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=2, model=GPT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dacfbf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is the president of Mexico?', 'result': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the president of Mexico?\"\n",
    "resonse = qa_without_source.invoke({\"query\": query})\n",
    "\n",
    "pprint.pprint(resonse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a65db0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The model (`gpt-5`) did a good job overall, although not perfect. I think all the answers are acceptable, except for the second one (\"When is the Day of the Dead traditionally celebrated?\"). The Wikipedia article clearly mentions this date (The Day of the Dead is a holiday traditionally celebrated on November 1 and 2, though other days, such as October 31 or November 6, may be included depending on the locality).\n",
    "\n",
    "When using a source that can be read quickly (such as this Wikipedia article), and we ask only a few questions, it's easy to spot the errors. However, when using a larger document (or multiple ones), or when several questions are asked, it is going to be more difficult to evaluate the accuracy of the model. It's important to keep this in mind, especially if we are dealing with sensitive or critical information.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
